// This file was generated by BAML: do not edit it.
// Instead, edit the BAML source files.
//
// Learn more at https://docs.boundaryml.com

//! Embedded BAML source files.

use std::collections::HashMap;
use std::sync::OnceLock;

static FILE_MAP: OnceLock<HashMap<String, String>> = OnceLock::new();

/// Get the embedded BAML source files.
pub fn get_baml_files() -> &'static HashMap<String, String> {
    FILE_MAP.get_or_init(|| {
        let mut m = HashMap::new();

        m.insert("agent.baml".to_string(), "// ChoirOS Chat Agent Functions\n// BAML-powered agent functions for planning and response synthesis\n\nfunction Decide(\n  messages: Message[],\n  context: string,\n  available_tools: string\n) -> AgentDecision {\n  client Orchestrator\n  prompt #\"\n    You are ChoirOS, an intelligent AI assistant.\n\n    {{ context }}\n\n    Available Tools:\n    {{ available_tools }}\n\n    Conversation:\n    {{ messages }}\n\n    Decide what to do next:\n    - If more evidence or actions are needed, return one or more tool_calls\n    - If you have enough information, include a `finished` tool call and put the final answer in message\n\n    Tool-use guidelines:\n    - For external, time-sensitive, or verifiable requests, use tools instead of guessing\n    - Resolve relative time references against the current context\n    - Call multiple tools in parallel when independent\n    - If `message_writer` is available, use it for actor-to-actor updates/completion before calling `finished`\n    - For each tool call, use exactly one schema variant matching the tool_name\n    - Include only valid fields for that tool's args and omit absent optional fields\n    - Never emit placeholder keys with null values\n    - Always set message:\n      - With tool calls: brief execution plan for this step\n      - With `finished`: direct final answer\n    - Once you have sufficient evidence, call `finished` and provide the final answer in message\n\n    {{ ctx.output_format(prefix=\"Return only valid JSON.\\n\", or_splitter=\" | \", hoist_classes=true) }}\n  \"#\n}\n\n// Quick response for simple queries (no tool use)\nfunction QuickResponse(\n  user_message: string,\n  conversation_history: string\n) -> string {\n  client FastResponse\n  prompt #\"\n    You are ChoirOS, a helpful AI assistant.\n\n    Conversation History:\n    {{ conversation_history }}\n\n    User: {{ user_message }}\n\n    Provide a brief, helpful response.\n  \"#\n}\n".to_string());

        m.insert("clients.baml".to_string(), "// ChoirOS Chat Agent Clients\n// Semantic client names for role-based model routing.\n// Actual providers are configured at runtime via ClientRegistry.\n\n// Orchestrator: High-quality model for complex reasoning and orchestration\nclient<llm> Orchestrator {\n  provider aws-bedrock\n  retry_policy Exponential\n  options {\n    model \"us.anthropic.claude-opus-4-5-20251101-v1:0\"\n    region \"us-east-1\"\n    // No explicit auth needed - provider auto-detects AWS_BEARER_TOKEN_BEDROCK\n  }\n}\n\n// FastResponse: Fast/cheap model for quick responses and high-volume tasks\nclient<llm> FastResponse {\n  provider anthropic\n  retry_policy Exponential\n  options {\n    api_key env.ZAI_API_KEY\n    base_url \"https://api.z.ai/api/anthropic\"\n    model \"glm-4.7\"\n  }\n}\n\n// Retry policies\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n".to_string());

        m.insert("conductor.baml".to_string(), "// ChoirOS Conductor BAML Contracts\n// Orchestration functions for the Conductor actor to manage multi-step agent workflows\n\n// ============================================================================\n// Simplified Decision Types\n// ============================================================================\n\nenum ConductorAction {\n  SpawnWorker\n  AwaitWorker\n  MergeCanon\n  Complete\n  Block\n  /// Phase 4: Spawn a focused sub-agent for a bounded scoped task.\n  SpawnSubharness\n  /// Phase 4: Delegate a task to a named app-level worker.\n  Delegate\n}\n\n// ---------------------------------------------------------------------------\n// Phase 4 — WorkerKind\n// ---------------------------------------------------------------------------\n\nenum WorkerKind {\n  Researcher\n  Writer\n  Terminal\n  Subharness\n}\n\n// ---------------------------------------------------------------------------\n// Phase 4 — Extended ConductorDecision\n// ---------------------------------------------------------------------------\n\nclass ConductorDecision {\n  action ConductorAction\n  args map<string, string>?\n  reason string\n  /// Only set when action == SpawnSubharness.\n  subharness_task string?\n  /// Only set when action == Delegate.\n  delegate_worker WorkerKind?\n  delegate_task string?\n}\n\nclass ConductorDecisionInput {\n  run_id string\n  objective string\n  document_path string\n  last_error string?\n}\n\nfunction ConductorDecide(input: ConductorDecisionInput) -> ConductorDecision {\n  client Orchestrator\n  prompt #\"\n    You are the ChoirOS Conductor, an orchestration AI.\n\n    Current Run:\n    - Run ID: {{ input.run_id }}\n    - Objective: {{ input.objective }}\n    - Document: {{ input.document_path }}\n    {% if input.last_error %}\n    - Last Error: {{ input.last_error }}\n    {% endif %}\n\n    Read the living document at {{ input.document_path }} to understand the current state.\n\n    Decide the next action:\n    - **SpawnWorker**: Dispatch a worker (researcher, terminal) with an objective\n    - **AwaitWorker**: Wait for pending worker calls to complete\n    - **MergeCanon**: Merge completed worker proposals into canon\n    - **Complete**: The objective is achieved\n    - **Block**: Cannot proceed (error or needs human help)\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// ============================================================================\n// Function: ConductorRefineObjective\n// ============================================================================\n\nclass ConductorObjectiveRefineInput {\n  raw_objective string\n  context string[]\n  target_capability string\n}\n\nclass ConductorObjectiveRefineOutput {\n  refined_objective string\n  success_criteria string[]\n  estimated_steps int\n  confidence float\n}\n\nfunction ConductorRefineObjective(input: ConductorObjectiveRefineInput) -> ConductorObjectiveRefineOutput {\n  client Orchestrator\n  prompt #\"\n    You are the ChoirOS Conductor, refining user objectives into clear, actionable tasks for capability workers.\n\n    Raw Objective: {{ input.raw_objective }}\n\n    Target Capability: {{ input.target_capability }}\n\n    Context from Previous Worker Outputs:\n    {{ input.context }}\n\n    Your task is to transform the raw objective into a refined, actionable objective specifically tailored for the target capability.\n\n    Refinement Guidelines:\n    1. Make the objective specific and unambiguous\n    2. Include relevant context from previous outputs\n    3. Frame it in terms the target capability understands\n    4. Define clear success criteria (3-5 specific, measurable outcomes)\n    5. Estimate the number of steps required (1-10)\n    6. Set confidence based on clarity of the refinement (0.0-1.0)\n\n    Success Criteria Guidelines:\n    - Each criterion should be verifiable\n    - Use specific metrics where possible\n    - Include both positive outcomes and negative constraints\n    - Consider edge cases and error conditions\n\n    Example Transformations:\n    - Raw: \"Research this topic\" -> Refined: \"Search for recent academic papers on X published in 2024, extract key findings, and summarize methodology\"\n    - Raw: \"Fix the bug\" -> Refined: \"Analyze the error logs in /var/log/app.log, identify the root cause of the timeout issue, and implement a fix with test coverage\"\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// ============================================================================\n// Function: ConductorBootstrapAgenda\n// ============================================================================\n\nclass ConductorBootstrapInput {\n  raw_objective string\n  available_capabilities string[]\n}\n\nclass ConductorBootstrapOutput {\n  dispatch_capabilities string[]\n  block_reason string?\n  rationale string\n  confidence float\n}\n\nfunction ConductorBootstrapAgenda(input: ConductorBootstrapInput) -> ConductorBootstrapOutput {\n  client Orchestrator\n  prompt #\"\n    You are the ChoirOS Conductor bootstrap policy.\n\n    Choose which capabilities should be dispatched first for a new run.\n\n    Raw Objective: {{ input.raw_objective }}\n    Available Capabilities: {{ input.available_capabilities }}\n\n    Output contract:\n    - dispatch_capabilities may include zero, one, or many capability names.\n    - Only return capability names from available_capabilities.\n    - Conductor routes app-level capabilities (for example: writer, immediate_response), not worker roles.\n    - Do not return worker names such as researcher or terminal unless explicitly present in available_capabilities.\n    - Use immediate_response only for short conversational acknowledgements (for example: hi, ping, quick status checks).\n    - Return zero capabilities when the run should be blocked immediately.\n    - If dispatch_capabilities is empty, block_reason is required.\n    - rationale must explain why these capabilities were selected.\n    - confidence is 0.0-1.0.\n    - Avoid deterministic threshold logic and use semantic task fit.\n\n    {{ ctx.output_format }}\n  \"#\n}\n".to_string());

        m.insert("generators.baml".to_string(), "// BAML Generator for Rust - ChoirOS Chat Agent\n// This generates Rust code for BAML functions\n\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"go\", \"rust\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"rust\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../sandbox/src\"\n\n    // The version of the BAML package you have installed\n    version \"0.217.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n".to_string());

        m.insert("researcher.baml".to_string(), "// ChoirOS Researcher BAML Contracts - DEPRECATED\n//\n// DEPRECATION NOTICE (2026-02-11):\n// The ResearcherActor now uses the unified agent harness (agent_harness module)\n// with the standard Decide function from agent.baml. These types and the\n// ResearcherPlanStep function are kept for backward compatibility but are\n// no longer used by the main researcher loop.\n//\n// The researcher now follows the standard pattern:\n//   DECIDE (via PlanAction/Decide) -> EXECUTE tools -> loop or return\n//\n// Tool execution is handled by ResearcherAdapter which implements AgentAdapter.\n\n// ============================================================================\n// Status Enums (kept for backward compatibility)\n// ============================================================================\n\nenum ResearchStatus {\n  Ongoing    // Still researching, gathering information\n  Complete   // Satisfied with the answer\n  Blocked    // Cannot proceed (insufficient info, access issues, etc.)\n}\n\n// ============================================================================\n// Planning Types (kept for backward compatibility)\n// ============================================================================\n\nclass ResearcherPlanInput {\n  objective string\n  current_query string\n  round int\n  max_rounds int\n  working_draft_path string  // Path to the current working draft file\n  last_error string?\n}\n\nclass ResearcherPlanOutput {\n  action ResearchAction        // What to do next\n  query string?                // If searching\n  provider string?             // Search provider hint\n  url string?                  // If fetching\n  file_path string?            // If reading/writing file\n  content string?              // If writing to file\n  old_text string?             // If editing file (text to replace)\n  new_text string?             // If editing file (replacement text)\n  reason string                // Why this action was chosen\n  status ResearchStatus        // Current research status\n}\n\nenum ResearchAction {\n  Search       // Perform web search\n  FetchUrl     // Fetch specific URL\n  FileRead     // Read local file\n  FileWrite    // Write/create file\n  FileEdit     // Edit existing file\n  Complete     // Research is complete\n  Block        // Cannot proceed\n}\n\n// ============================================================================\n// Functions (DEPRECATED - use Decide from agent.baml instead)\n// ============================================================================\n\nfunction ResearcherPlanStep(input: ResearcherPlanInput) -> ResearcherPlanOutput {\n  client FastResponse\n  prompt #\"\n    DEPRECATED: This function is kept for backward compatibility.\n    The ResearcherActor now uses the unified agent harness with Decide.\n\n    You are the ChoirOS Researcher. Your job is to gather information and maintain a working draft document.\n\n    Objective: {{ input.objective }}\n    Current Query: {{ input.current_query }}\n    Round: {{ input.round }} / {{ input.max_rounds }}\n    Working Draft: {{ input.working_draft_path }}\n    Last Error: {{ input.last_error }}\n\n    Available Actions:\n    - Search: Use web_search with query and optional provider (tavily, brave, exa, auto)\n    - FetchUrl: Use fetch_url to retrieve content from a specific URL\n    - FileRead: Read an existing file to reference previous research or context\n    - FileWrite: Create or overwrite a file (usually your working draft)\n    - FileEdit: Modify specific text in an existing file (preserves what you don't change)\n    - Complete: Mark research as done when you have a satisfactory answer\n    - Block: Mark as blocked if you cannot proceed\n\n    Working Document Strategy:\n    - Start by writing an initial draft with your plan\n    - Update the draft as you discover new information\n    - Use FileEdit to refine specific sections without rewriting everything\n    - The draft should evolve from \"plan\" → \"notes\" → \"findings\" → \"final answer\"\n    - Write in freeform markdown - no forced structure\n    - Put the most important finding first (don't bury the lede)\n\n    Guidelines:\n    - Be concise in your writing - update the draft frequently\n    - Cite sources inline as markdown links: [title](url)\n    - If a search returns little, try a different query or provider\n    - Read existing files if the objective references local content\n    - When Complete, ensure the working draft contains your final answer\n\n    {{ ctx.output_format }}\n  \"#\n}\n".to_string());

        m.insert("resume.baml".to_string(), "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // You can also use custom LLM params with a custom client name from clients.baml like \"client CustomGPT5\" or \"client CustomSonnet4\"\n  client \"openai-responses/gpt-5-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n".to_string());

        m.insert("rlm.baml".to_string(), "// ChoirOS RLM (Recursive Language Model) Harness Contract\n//\n// The RLM harness is the GENERAL execution mode. The model outputs a program\n// each turn that specifies:\n//   1. What context to load (sources)\n//   2. Its reasoning state (working_memory)\n//   3. What to do next (next_action)\n//\n// Linear tool loops are NextAction::ToolCalls — one degenerate case.\n// Conductor single-shot is an RLM with max_turns=1.\n// Everything is an RLM.\n\n// ============================================================================\n// Context Sources — the model selects what to include each turn\n// ============================================================================\n\nenum ContextSourceKind {\n  /// Query episodic memory for relevant patterns\n  MemoryQuery\n  /// Load a specific file or document\n  Document\n  /// Selectively include output from a previous turn (not automatic)\n  PreviousTurn\n  /// Include a specific tool execution result\n  ToolOutput\n}\n\nclass ContextSource {\n  kind ContextSourceKind\n  /// For MemoryQuery: the search query. For Document: the file path.\n  /// For PreviousTurn: turn number as string. For ToolOutput: call_id.\n  source_ref string\n  /// Why this source is needed (helps the harness prioritize under budget)\n  rationale string?\n  /// Max tokens to allocate to this source (model manages its own budget)\n  max_tokens int?\n}\n\n// ============================================================================\n// Next Action — the model controls topology\n// ============================================================================\n\nenum NextActionKind {\n  /// Execute tools sequentially (linear mode — the common/degenerate case)\n  ToolCalls\n  /// Execute a multi-step program (DAG of operations with variable refs,\n  /// conditionals, and embedded LLM calls). This is the computationally\n  /// universal execution mode. ToolCalls is sugar for a single-layer DAG\n  /// where every step is op=ToolCall with no dependencies.\n  Program\n  /// Spawn parallel branches with different approaches\n  FanOut\n  /// Delegate to a sub-harness with fresh context\n  Recurse\n  /// Terminal: objective achieved\n  Complete\n  /// Terminal: cannot proceed\n  Block\n}\n\nclass ToolCallSpec {\n  tool_name string\n  tool_args map<string, string>\n  reasoning string?\n}\n\n// ============================================================================\n// Execution DAG — the program the model writes\n// ============================================================================\n//\n// Each DagStep is a node. Steps reference other steps' outputs via\n// ${step_id} in their arguments. The harness executes in dependency order,\n// substituting resolved values. Steps can be conditional on prior step\n// outputs via the `condition` field.\n//\n// This is computationally universal: it has sequencing (deps), variables\n// (${ref}), conditionals (condition), I/O (ToolCall, Bash), and embedded\n// LLM calls (LlmCall). The harness traces every node.\n\nenum StepOp {\n  /// Execute a tool (bash, file_read, file_write, file_edit, web_search, fetch_url).\n  /// Same tools available as ToolCallSpec but within a DAG.\n  ToolCall\n\n  /// Call an LLM with a composed prompt. The prompt can reference prior\n  /// step outputs via ${step_id}. The harness resolves the model.\n  LlmCall\n\n  /// Pure string transformation: extract via regex, truncate, format.\n  /// No I/O, no side effects. The harness evaluates this locally.\n  Transform\n\n  /// Conditional gate: evaluate a predicate on a prior step's output.\n  /// Downstream steps with `condition: \"gate_step_id\"` only execute if\n  /// the gate evaluates to true. Predicates: contains, not_contains,\n  /// matches_regex, equals, not_equals.\n  Gate\n\n  /// Send a message to the parent actor (progress report, partial result).\n  Emit\n\n  /// Execute a Rhai script. The script has access to registered bindings:\n  ///   read_file(path)           -> String\n  ///   write_file(path, content) -> ()\n  ///   fetch_url(url)            -> String\n  ///   shell(cmd)                -> String\n  ///   call_llm(prompt)          -> String\n  ///   emit_msg(msg)             -> ()\n  ///   step_output(id)           -> String  (access prior step outputs)\n  /// The script's return value (last expression) becomes this step's output.\n  /// Use `eval_code` field for the script source. Prior step outputs are\n  /// available via step_output(\"step_id\") or pre-injected as variables\n  /// if listed in `eval_inputs`.\n  Eval\n}\n\nclass DagStep {\n  /// Unique identifier for this step within the DAG. Other steps reference\n  /// this via ${id} in their arguments.\n  id string\n\n  /// The operation to perform.\n  op StepOp\n\n  /// Step IDs that must complete before this step runs. The harness\n  /// enforces topological ordering. Empty = no dependencies (runs first).\n  depends_on string[]\n\n  /// If set, this step only executes when the named Gate step evaluated\n  /// to true. Skipped steps produce output \"(skipped)\".\n  condition string?\n\n  // ── Per-op arguments ──────────────────────────────────────────────\n\n  /// For ToolCall: the tool name (bash, file_read, etc.)\n  tool_name string?\n  /// For ToolCall: the tool arguments. Values can contain ${step_id}\n  /// refs which the harness substitutes with that step's output.\n  tool_args map<string, string>?\n\n  /// For LlmCall: the prompt to send. Can contain ${step_id} refs.\n  prompt string?\n  /// For LlmCall: optional model hint (e.g. \"fast\" for flash, \"strong\"\n  /// for opus). The harness resolves this to an actual model ID.\n  model_hint string?\n  /// For LlmCall: optional system prompt.\n  system_prompt string?\n\n  /// For Transform: the operation. Supported: \"regex\", \"truncate\",\n  /// \"json_extract\", \"template\".\n  transform_op string?\n  /// For Transform: the input (usually a ${step_id} ref).\n  transform_input string?\n  /// For Transform: the pattern or parameter.\n  /// For regex: the regex pattern (first capture group is output).\n  /// For truncate: max chars as string. For json_extract: the JSON path.\n  /// For template: a string with ${step_id} refs to interpolate.\n  transform_pattern string?\n\n  /// For Gate: the predicate to evaluate. Format: \"op:value\" where op\n  /// is one of contains, not_contains, matches, equals, not_equals.\n  /// The input is the output of the first dependency.\n  gate_predicate string?\n\n  /// For Emit: the message to send to the parent. Can contain ${refs}.\n  emit_message string?\n\n  /// For Eval: the Rhai script source code.\n  /// Prior step outputs can be accessed via step_output(\"id\") or via\n  /// variables pre-injected by listing their step IDs in `eval_inputs`.\n  eval_code string?\n  /// For Eval: step IDs whose outputs should be injected as variables.\n  /// E.g. if eval_inputs=[\"read\", \"analyze\"], the script can reference\n  /// variables `read` and `analyze` directly (as strings).\n  eval_inputs string[]?\n\n  /// Human-readable description of what this step does (for tracing).\n  description string?\n}\n\nclass FanOutBranch {\n  /// Objective for this branch\n  objective string\n  /// Optional: different model or config for this branch\n  model_hint string?\n  /// Context seed: what the branch starts with\n  context_seed string?\n}\n\nclass RecurseSpec {\n  /// Objective for the sub-harness\n  objective string\n  /// Context to pass to the child (not the full parent context)\n  context_seed string?\n  /// Optional model preference for the child\n  model_hint string?\n  /// Max steps for the child\n  max_steps int?\n}\n\nclass NextAction {\n  kind NextActionKind\n  /// For Complete/Block: the reason\n  reason string?\n  /// For ToolCalls: the tool invocations (simple linear case)\n  tool_calls ToolCallSpec[]?\n  /// For Program: the execution DAG (computationally universal case)\n  program DagStep[]?\n  /// For FanOut: the parallel branches\n  branches FanOutBranch[]?\n  /// For Recurse: the delegation spec\n  recurse RecurseSpec?\n}\n\n// ============================================================================\n// RLM Turn Output — the \"program\" the model writes each turn\n// ============================================================================\n\nclass RlmTurn {\n  /// What context to load for this turn. The harness resolves these into text.\n  /// Empty sources = the model is working from working_memory alone.\n  sources ContextSource[]\n\n  /// The model's articulation of its current reasoning state.\n  /// This carries focus across turns. It is ephemeral — rewritten each turn.\n  /// This IS the metacognition: the model reflecting on what it knows,\n  /// what it's uncertain about, and what it needs next.\n  working_memory string\n\n  /// What to do next. The harness executes this.\n  next_action NextAction\n}\n\n// ============================================================================\n// Turn Context — what the harness provides to the model each turn\n// ============================================================================\n\nclass RlmTurnContext {\n  /// The original objective (constant across turns)\n  objective string\n  /// Current turn number\n  turn_number int\n  /// Max turns remaining\n  max_turns int\n  /// The model's working_memory from the previous turn (empty on turn 1)\n  previous_working_memory string?\n  /// Resolved context from the previous turn's source requests\n  /// (assembled by the harness, not the model)\n  assembled_context string?\n  /// Results from the previous turn's action execution\n  action_results string?\n  /// Summary of all completed turns so far (compressed by harness)\n  turn_history_summary string?\n}\n\n// ============================================================================\n// The RLM Compose Function\n// ============================================================================\n\nfunction RlmCompose(turn_ctx: RlmTurnContext, capabilities: string) -> RlmTurn {\n  client Orchestrator\n  prompt #\"\n    You are operating within a Recursive Language Model (RLM) harness.\n\n    OBJECTIVE: {{ turn_ctx.objective }}\n    TURN: {{ turn_ctx.turn_number }}/{{ turn_ctx.max_turns }}\n\n    {% if turn_ctx.previous_working_memory %}\n    YOUR PREVIOUS WORKING MEMORY:\n    {{ turn_ctx.previous_working_memory }}\n    {% endif %}\n\n    {% if turn_ctx.assembled_context %}\n    ASSEMBLED CONTEXT (from your previous source requests):\n    {{ turn_ctx.assembled_context }}\n    {% endif %}\n\n    {% if turn_ctx.action_results %}\n    RESULTS FROM PREVIOUS ACTION:\n    {{ turn_ctx.action_results }}\n    {% endif %}\n\n    {% if turn_ctx.turn_history_summary %}\n    TURN HISTORY:\n    {{ turn_ctx.turn_history_summary }}\n    {% endif %}\n\n    CAPABILITIES:\n    {{ capabilities }}\n\n    YOUR TASK: Output an RlmTurn that specifies:\n\n    1. SOURCES — What context do you need? Request specific documents,\n       memory queries, or prior turn outputs. The harness will resolve\n       these and provide them on the next turn. Leave empty if you have\n       enough context already.\n\n    2. WORKING MEMORY — Articulate your current reasoning state. What do\n       you know? What are you uncertain about? What's your plan? This\n       carries your focus across turns. Be specific and concise.\n\n    3. NEXT ACTION — What to do now:\n       - ToolCalls: Execute tools sequentially (simple case, no dependencies between calls).\n       - Program: Execute a DAG of steps with dependencies, variable references,\n         conditionals, and embedded LLM calls. THIS IS THE POWERFUL MODE. Use it\n         when you need multi-step computation where later steps depend on earlier\n         outputs.\n       - FanOut: Spawn parallel branches when you need to explore alternatives.\n       - Recurse: Delegate a sub-task to a fresh harness with its own context.\n       - Complete: You're done. Provide the final answer in reason.\n       - Block: You can't proceed. Explain why in reason.\n\n    PROGRAM (DAG) AUTHORING:\n    When you choose kind=Program, populate the `program` field with DagStep objects.\n    Each step has an `id` and an `op`:\n\n    - ToolCall: Execute a tool. Set tool_name and tool_args.\n    - LlmCall: Call an LLM. Set prompt (and optionally model_hint, system_prompt).\n    - Transform: Pure string manipulation. Set transform_op, transform_input, transform_pattern.\n      Ops: \"regex\" (first capture group), \"truncate\" (max chars), \"json_extract\" (path), \"template\" (interpolate).\n    - Gate: Conditional. Set gate_predicate as \"op:value\" (contains, not_contains, matches, equals, not_equals).\n      Downstream steps set condition=gate_step_id to only run if the gate is true.\n    - Emit: Report to parent. Set emit_message.\n    - Eval: Execute a Rhai script. Set eval_code with the Rhai source. Available bindings:\n        read_file(path) -> String, write_file(path, content),\n        fetch_url(url) -> String, shell(cmd) -> String,\n        call_llm(prompt) -> String, emit_msg(msg),\n        step_output(id) -> String (access prior step output by ID).\n      Optionally set eval_inputs to a list of step IDs — their outputs are injected as\n      same-named variables (e.g. eval_inputs:[\"read\"] → variable `read` is available).\n      The script's last expression is the step output.\n\n    Variable references: Use ${step_id} in any string argument to inject that step's output.\n    Dependencies: Set depends_on to list step IDs that must complete first.\n    The harness executes in topological order and traces every step.\n\n    EXAMPLE PROGRAM (analyze a file, conditionally deep-review):\n    [\n      { id: \"read\", op: ToolCall, depends_on: [], tool_name: \"file_read\", tool_args: { \"path\": \"src/auth.rs\" } },\n      { id: \"analyze\", op: LlmCall, depends_on: [\"read\"], prompt: \"Analyze for security issues:\\n${read}\" },\n      { id: \"is_critical\", op: Gate, depends_on: [\"analyze\"], gate_predicate: \"contains:CRITICAL\" },\n      { id: \"deep\", op: LlmCall, depends_on: [\"read\", \"analyze\"], condition: \"is_critical\",\n        prompt: \"Deep security review of:\\n${read}\\n\\nInitial analysis:\\n${analyze}\", model_hint: \"strong\" },\n      { id: \"report\", op: Emit, depends_on: [\"analyze\", \"deep\"],\n        emit_message: \"Security review complete. ${deep}\" }\n    ]\n\n    GUIDELINES:\n    - Use ToolCalls for simple one-or-two-step actions with no dependencies between them.\n    - Use Program when steps depend on each other's outputs, or when you need\n      conditionals, LLM calls within the execution, or multi-stage data transformation.\n    - Use FanOut when multiple approaches seem viable and you need to explore.\n    - Use Recurse when a sub-task is complex enough to benefit from fresh context.\n    - Your working_memory is your scratch pad — use it to think out loud.\n    - You control your own context. Don't ask for sources you don't need.\n    - If you have enough information, go straight to Complete.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// ============================================================================\n// Freeform LLM Call — used by DAG executor for embedded LlmCall steps\n// ============================================================================\n\nfunction DagLlmCall(prompt: string, system_prompt: string?) -> string {\n  client Orchestrator\n  prompt #\"\n    {% if system_prompt %}\n    {{ system_prompt }}\n    {% endif %}\n\n    {{ prompt }}\n  \"#\n}\n".to_string());

        m.insert("types.baml".to_string(), "// ChoirOS Chat Agent Types\n// Core types for BAML-powered chat agent with tool execution\n\n// Message in conversation\nclass Message {\n  role string\n  content string\n}\n\nclass BashToolArgs {\n  command string\n}\n\nclass WebSearchToolArgs {\n  query string\n}\n\nclass FetchUrlToolArgs {\n  path string\n}\n\nclass FileReadToolArgs {\n  path string\n}\n\nclass FileWriteToolArgs {\n  path string\n  content string\n}\n\nclass FileEditToolArgs {\n  path string\n  old_text string\n  new_text string\n}\n\nclass MessageWriterToolArgs {\n  content string\n  mode string\n  path string?\n  mode_arg string?\n}\n\nclass FinishedToolArgs {\n  summary string?\n}\n\nclass BashToolCall {\n  tool_name \"bash\"\n  tool_args BashToolArgs\n  reasoning string?\n}\n\nclass WebSearchToolCall {\n  tool_name \"web_search\"\n  tool_args WebSearchToolArgs\n  reasoning string?\n}\n\nclass FetchUrlToolCall {\n  tool_name \"fetch_url\"\n  tool_args FetchUrlToolArgs\n  reasoning string?\n}\n\nclass FileReadToolCall {\n  tool_name \"file_read\"\n  tool_args FileReadToolArgs\n  reasoning string?\n}\n\nclass FileWriteToolCall {\n  tool_name \"file_write\"\n  tool_args FileWriteToolArgs\n  reasoning string?\n}\n\nclass FileEditToolCall {\n  tool_name \"file_edit\"\n  tool_args FileEditToolArgs\n  reasoning string?\n}\n\nclass MessageWriterToolCall {\n  tool_name \"message_writer\"\n  tool_args MessageWriterToolArgs\n  reasoning string?\n}\n\nclass FinishedToolCall {\n  tool_name \"finished\"\n  tool_args FinishedToolArgs\n  reasoning string?\n}\n\n// Simplified agent decision - what to do next\nclass AgentDecision {\n  tool_calls (BashToolCall | WebSearchToolCall | FetchUrlToolCall | FileReadToolCall | FileWriteToolCall | FileEditToolCall | MessageWriterToolCall | FinishedToolCall)[]  // Completion requires a finished tool call\n  message string\n}\n\n// Result of executing a tool\nclass ToolResult {\n  tool_name string\n  success bool\n  output string\n  error string?\n}\n\n// Streaming chunk types for WebSocket\nclass StreamChunk {\n  chunk_type string // \"thinking\", \"tool_call\", \"tool_result\", \"response\", \"error\"\n  content string\n}\n\n// ---------------------------------------------------------------------------\n// Phase 2.2 — Citation Types\n// ---------------------------------------------------------------------------\n\n/// Why a resource was cited by a researcher or writer.\nenum CitationKind {\n  /// Researcher retrieved the resource and pulled it into context.\n  RetrievedContext\n  /// Appears as a link or inline reference in document text.\n  InlineReference\n  /// This run extends or revises the cited artifact.\n  BuildsOn\n  /// Explicitly disputes a prior artifact.\n  Contradicts\n  /// Restates a prior objective or directive.\n  Reissues\n}\n\n/// A single citation proposed by the researcher or confirmed/rejected by the writer.\nclass Citation {\n  /// Artifact path, version_id, input_id, URL, or block_id.\n  cited_id string\n  cite_kind CitationKind\n  /// Model confidence in this citation [0.0, 1.0].\n  confidence float\n  /// Specific text span that triggered this citation, if extractable.\n  excerpt string?\n  /// Why this citation was relevant.\n  rationale string\n}\n".to_string());

        m.insert("watcher.baml".to_string(), "// ChoirOS Watcher BAML Contracts\n// Event-log review and escalation functions for the Watcher actor\n//\n// The Watcher provides deterministic detection/alerting over logs.\n// These BAML functions enable LLM-powered review of event windows for\n// anomaly detection and mitigation recommendations.\n\n// ============================================================================\n// Input Types\n// ============================================================================\n\nclass WatcherLogWindowInput {\n  window_id string\n  run_id string\n  task_id string\n  events WatcherEvent[]\n  scope ReviewScope\n  review_reason string?  // Why this window is being reviewed\n}\n\nclass WatcherEvent {\n  event_id string\n  timestamp string\n  event_type string\n  level string  // info, warn, error, critical\n  payload string\n  source string  // which component emitted\n}\n\nclass ReviewScope {\n  start_time string\n  end_time string\n  event_types string[]\n  min_level string\n}\n\n// ============================================================================\n// Output Types - Review\n// ============================================================================\n\nenum ReviewStatus {\n  Clean\n  IssuesDetected\n  Critical\n  Inconclusive\n}\n\nenum EscalationKind {\n  FailureSpike\n  TimeoutPattern\n  ResourceExhaustion\n  SecurityConcern\n  CostAnomaly\n  StalledWorkflow\n  Other\n}\n\nenum UrgencyLevel {\n  Low\n  Medium\n  High\n  Critical\n}\n\nenum RiskCategory {\n  Operational\n  Technical\n  Security\n  Cost\n  Compliance\n}\n\nclass WatcherReviewOutput {\n  review_status ReviewStatus\n  escalations WatcherEscalation[]\n  risks RiskItem[]\n  anomalies DetectedAnomaly[]\n  confidence float\n  rationale string\n}\n\nclass WatcherEscalation {\n  escalation_id string\n  run_id string\n  task_id string\n  kind EscalationKind\n  urgency UrgencyLevel\n  affected_calls string[]\n  description string\n  recommended_action string\n  recommended_capability string?\n  recommended_objective string?\n}\n\nclass RiskItem {\n  risk_id string\n  category RiskCategory\n  likelihood float  // 0.0-1.0\n  impact float  // 0.0-1.0\n  description string\n  mitigating_factors string[]\n}\n\nclass DetectedAnomaly {\n  anomaly_type string\n  severity string\n  description string\n  affected_events string[]\n  pattern_detected string\n}\n\n// ============================================================================\n// Input Types - Mitigation\n// ============================================================================\n\nclass WatcherMitigationInput {\n  escalation WatcherEscalation\n  run_state RunStateSnapshot\n  available_capabilities string[]\n  historical_resolutions HistoricalResolution[]\n}\n\nclass RunStateSnapshot {\n  run_id string\n  status string\n  active_call_count int\n  recent_failures int\n  elapsed_time_ms int\n}\n\nclass HistoricalResolution {\n  pattern string\n  successful_resolution string\n  resolution_type string\n}\n\n// ============================================================================\n// Output Types - Mitigation\n// ============================================================================\n\nenum EscalationAction {\n  NotifyConductor\n  RequestHumanReview\n  AutoRetry\n  ScaleResources\n  TerminateRun\n  ContinueMonitoring\n  EscalateToOnCall\n}\n\nclass WatcherMitigationOutput {\n  escalation_action EscalationAction\n  urgency UrgencyLevel\n  recommended_capability string?\n  recommended_objective string?\n  rationale string\n  confidence float\n  expected_outcome string\n  alternatives AlternativeAction[]\n}\n\nclass AlternativeAction {\n  action EscalationAction\n  pros string[]\n  cons string[]\n  estimated_success_rate float\n}\n\n// ============================================================================\n// Function 1: WatcherReviewLogWindow\n// ============================================================================\n\nfunction WatcherReviewLogWindow(input: WatcherLogWindowInput) -> WatcherReviewOutput {\n  client FastResponse\n  prompt #\"\n    You are the ChoirOS Watcher, an AI that reviews event logs for anomalies,\n    failures, and concerning patterns.\n\n    Your role is deterministic detection over logs - you identify issues that\n    may require escalation to the Conductor or human operators.\n\n    Window ID: {{ input.window_id }}\n    Run ID: {{ input.run_id }}\n    Task ID: {{ input.task_id }}\n\n    Review Reason: {{ input.review_reason }}\n\n    Review Scope:\n    - Start Time: {{ input.scope.start_time }}\n    - End Time: {{ input.scope.end_time }}\n    - Event Types: {{ input.scope.event_types }}\n    - Minimum Level: {{ input.scope.min_level }}\n\n    Events to Review ({{ input.events | length }} events):\n    {{ input.events }}\n\n    Review Guidelines:\n\n    1. **ReviewStatus Classification**:\n       - Clean: No issues detected, normal operation\n       - IssuesDetected: Minor issues found, may need attention\n       - Critical: Serious problems requiring immediate escalation\n       - Inconclusive: Cannot determine from available data\n\n    2. **Escalation Detection** - Create escalations for:\n       - FailureSpike: Multiple failures in short window\n       - TimeoutPattern: Repeated timeout errors\n       - ResourceExhaustion: High resource usage or limits hit\n       - SecurityConcern: Suspicious activity or auth failures\n       - CostAnomaly: Unexpected cost patterns\n       - StalledWorkflow: Tasks not progressing\n       - Other: Unclassified but concerning patterns\n\n    3. **Risk Assessment**:\n       - Evaluate likelihood (0.0-1.0) and impact (0.0-1.0)\n       - Categories: Operational, Technical, Security, Cost, Compliance\n       - List mitigating factors that reduce risk\n\n    4. **Anomaly Detection**:\n       - Identify unusual patterns in event sequences\n       - Note severity and affected events\n       - Describe the pattern detected (e.g., \"retry storm\", \"cascade failure\")\n\n    5. **Escalation Recommendations**:\n       - recommended_action: Clear, actionable next step\n       - recommended_capability: Which capability should handle this (if known)\n       - recommended_objective: What objective to assign (if applicable)\n       - urgency: Low, Medium, High, or Critical\n\n    Output Requirements:\n    - Use exact enum values for ReviewStatus, EscalationKind, UrgencyLevel, RiskCategory\n    - Confidence score 0.0-1.0 based on clarity of findings\n    - Provide clear rationale for all escalations and risks\n    - affected_calls should reference specific call IDs from events\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// ============================================================================\n// Function 2: WatcherRecommendMitigation\n// ============================================================================\n\nfunction WatcherRecommendMitigation(input: WatcherMitigationInput) -> WatcherMitigationOutput {\n  client FastResponse\n  prompt #\"\n    You are the ChoirOS Watcher, recommending mitigation actions for detected issues.\n\n    Your role is to select the best action given an escalation and current run state,\n    including when to auto-retry vs request human review.\n\n    Escalation Details:\n    - ID: {{ input.escalation.escalation_id }}\n    - Kind: {{ input.escalation.kind }}\n    - Urgency: {{ input.escalation.urgency }}\n    - Description: {{ input.escalation.description }}\n    - Affected Calls: {{ input.escalation.affected_calls }}\n    - Recommended Action: {{ input.escalation.recommended_action }}\n    - Recommended Capability: {{ input.escalation.recommended_capability }}\n    - Recommended Objective: {{ input.escalation.recommended_objective }}\n\n    Current Run State:\n    - Run ID: {{ input.run_state.run_id }}\n    - Status: {{ input.run_state.status }}\n    - Active Calls: {{ input.run_state.active_call_count }}\n    - Recent Failures: {{ input.run_state.recent_failures }}\n    - Elapsed Time (ms): {{ input.run_state.elapsed_time_ms }}\n\n    Available Capabilities:\n    {{ input.available_capabilities }}\n\n    Historical Resolutions (similar patterns and their outcomes):\n    {{ input.historical_resolutions }}\n\n    Mitigation Guidelines:\n\n    1. **EscalationAction Selection**:\n       - NotifyConductor: Wake the Conductor for orchestration decision\n       - RequestHumanReview: Human judgment needed (ambiguous, high-stakes)\n       - AutoRetry: Safe to retry automatically (transient failures)\n       - ScaleResources: Increase resources (resource exhaustion)\n       - TerminateRun: Stop the run (unrecoverable, dangerous)\n       - ContinueMonitoring: Watch but don't act yet (inconclusive)\n       - EscalateToOnCall: Page the on-call engineer (critical production issue)\n\n    2. **Decision Matrix**:\n       - Transient failures (network, timeout) + low retry count -> AutoRetry\n       - Resource exhaustion + scaling available -> ScaleResources\n       - Ambiguous situation + high stakes -> RequestHumanReview\n       - Conductor available + complex coordination needed -> NotifyConductor\n       - Critical urgency + production impact -> EscalateToOnCall\n       - Unclear pattern + no historical success -> ContinueMonitoring\n\n    3. **Alternative Actions**:\n       - List 2-3 alternative actions with pros/cons\n       - Estimate success rate for each alternative\n       - Explain why the primary action was chosen\n\n    4. **Capability/Objectives**:\n       - recommended_capability: Which capability to invoke (if action requires it)\n       - recommended_objective: Clear objective statement for the capability\n       - These flow into the Conductor wake lane for orchestration\n\n    Output Requirements:\n    - Use exact enum values for EscalationAction and UrgencyLevel\n    - Confidence score 0.0-1.0 based on certainty of recommendation\n    - Provide clear rationale linking escalation to chosen action\n    - expected_outcome: What should happen if action is taken\n    - Include at least 2 alternatives with honest pros/cons\n\n    {{ ctx.output_format }}\n  \"#\n}\n".to_string());

        m.insert("writer.baml".to_string(), "// ChoirOS Writer BAML Contracts\n// Changeset summarization for Marginalia observation UX.\n\n// ============================================================================\n// Input Types\n// ============================================================================\n\nclass ChangesetInput {\n  patch_id string\n  loop_id string?\n  before_content string   // document content before the patch (may be empty)\n  after_content string    // document content after the patch\n  ops_json string         // JSON-serialized Vec<PatchOp> for context\n  source string           // who/what produced the change (writer, user, conductor, etc.)\n}\n\n// ============================================================================\n// Output Types\n// ============================================================================\n\nenum ImpactLevel {\n  Low\n  Medium\n  High\n}\n\nclass ChangesetSummaryOutput {\n  summary string        // 1-2 sentence human-readable description of what changed\n  impact ImpactLevel    // estimated scope of change\n  op_taxonomy string[]  // list of change categories present (e.g. [\"insert\", \"structural_rewrite\", \"clarification\"])\n}\n\n// ============================================================================\n// Function\n// ============================================================================\n\nfunction SummarizeChangeset(input: ChangesetInput) -> ChangesetSummaryOutput {\n  client FastResponse\n  prompt #\"\n    You are the ChoirOS Marginalia observer. Your job is to produce a compact,\n    human-readable summary of what changed in a document patch.\n\n    Patch ID: {{ input.patch_id }}\n    Source: {{ input.source }}\n    Loop ID: {{ input.loop_id }}\n\n    Before (may be empty if this is the first version):\n    {{ input.before_content }}\n\n    After:\n    {{ input.after_content }}\n\n    Raw ops (JSON for reference):\n    {{ input.ops_json }}\n\n    Instructions:\n    - Write a 1-2 sentence summary describing what changed and why it matters.\n    - Choose ImpactLevel:\n      - Low: minor wording tweaks, small additions or deletions\n      - Medium: one or more paragraphs changed, structural reorganization of a section\n      - High: large-scale rewrite, major content addition or deletion, objective changed\n    - List op_taxonomy categories that apply (pick from: insert, delete, replace, structural_rewrite,\n      clarification, expansion, condensation, reformatting, factual_update, objective_change).\n    - Keep the summary factual; do not speculate about intent beyond what the diff shows.\n\n    {{ ctx.output_format }}\n  \"#\n}\n".to_string());

        m
    })
}